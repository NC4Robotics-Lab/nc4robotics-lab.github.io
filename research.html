<!DOCTYPE html>
<html lang="en">
<<<<<<< HEAD
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>NC4Robotics-Lab | Research</title>
  <link rel="stylesheet" href="styles.css">
 <style>
    .sub-project {
      margin-bottom: 30px;
    }
    .sub-project img {
      max-width: 100%;
      height: auto;
      display: block;
      margin-top: 10px;
    }
    .sub-project-description {
      font-style: normal;
      text-align: justify;
      margin-top: 5px;
    }
  </style>
</head>
<body>
  <header>
    <h1>Neuromorphic Computing for Robotics &amp; AI Lab</h1>
    <nav>
      <ul>
        <li><a href="index.html" class="active">Home</a></li>
        <li><a href="research.html">Research</a></li>
        <li><a href="tutorials.html">Tutorials</a></li>
        <li><a href="team.html">Team</a></li>
        <li><a href="about.html">About</a></li>
      </ul>
    </nav>
  </header>

  <main>
    <h2>Neuromorphic Computing for Marine Robots</h2>
    <div class="sub-project">
      <p><strong><em>SNN-based Visibility Enhancement of Underwater Scenes</em></strong></p>
      <img src="images/uie_snn.png" alt="UIE-SNN">
      <p class="sub-project-description">We introduce UIE-SNN, the first spiking neural network (SNN)-based underwater image enhancement (UIE) algorithm to improve the overall visibility of underwater images. UIE-SNN is a 19- layered convolutional spiking encoder-decoder framework with skip connections, directly trained using surrogate gradient-based backpropagation through time (BPTT) strategy. We explore and validate the impact of training datasets on energy reduction, a unique advantage of the UIE-SNN architecture over conventional learning-based architectures, where energy consumption is model-dependent. UIE-SNN optimizes the loss function in latent space representation to reconstruct clear underwater images. Our algorithm demonstrates equivalent performance with its non-spiking counterpart methods in terms of PSNR and structural similarity index (SSIM) at reduced timesteps of 5 and energy consumption of 85%. The algorithm is trained on two publicly available benchmark datasets, UIEB and EUVP, and tested on unseen images from UIEB, EUVP, LSUI, U45, and our custom UIE dataset. Compared with the existing state-of-the-art UIE methods, UIE-SNN achieves an average of 6.5× improvement in energy efficiency. The main contributions are:</p>
  <ul>
    <li>Proposed UIE-SNN, the first directly trained convolutional SNN framework for UIE tasks</li>
    <li>Achieved comparable performance with its non-spiking counterpart (CNN-based) with 85% less energy.</li>
    <li>Demonstrated average improvement of 6.5× in energy efficiency compared to the existing UIE methods.</li>
    <li>Analyzed the impact of data representation on energy efficiency in UIE-SNN.</li>
    <li>Explored how neuronal parameter selection affects UIE-SNN performance.</li>
  </ul>
  <p><a href="https://arxiv.org/abs/2503.20485" target="_blank">Read the related article for more details.</a></p>
    </div>

    <div class="sub-project">
      <p><strong><em>Spiking Transformer with Adaptive Threshold Mechanism for Underwater Image Dehazing</em></strong></p>
      <img src="images/snntrans.png" alt="snnTrans-DHZ">
      <p class="sub-project-description">We introduce snnTrans-DHZ, the first spiking transformer with learnable threshold based underwater image dehazing algorithm with only 0.56M parameters to improve the visibility of underwater images.  sing the temporal dynamics of SNNs, snnTrans-DHZ efficiently processes time-dependent raw image sequences while maintaining low power consumption. The raw underwater images are first converted into time-dependent image sequences by repeatedly passing the static image to a user-defined timestep value. The RGB sequences are then converted into LAB color space representations and processed simultaneously. The architecture integrates three primary modules:(i) K estimator module to extract features from different color space representations, (ii) Background light estimator module to jointly estimate the background light component from the RGB-LAB color space representations, and (iii) soft image reconstruction module to reconstruct the haze-free, visibility-enhanced image. snnTrans-DHZ model is directly trained using surrogate gradient-based backpropagation through time (BPTT) strategy. In this research, a combined loss function is designed and used. Our model is trained and tested on the UIEB and EUVP, the two publicly available benchmark dataset for image dehazing. Our algorithm achieves a PSNR and SSIM of 21.6773 dB and 0.8795 on UIEB dataset, and 23.4562 dB and 0.8439 on EUVP dataset respectively. snnTrans-DHZ algorithm achieves this algorithmic performance with fewer operations (7.42 GSOPs) and lower energy consumption of 0.0151 J compared to existing state-of-the-art image enhancement methods.  Compared with the existing state-of-the-art lightest UIE method, our proposed algorithm achieves an average of 3.3× improvement in energy efficiency. The main contributions are:</p>
<ul>
    <li>Proposed snnTrans-DHZ algorithm, the first spiking transformer with learnable threshold framework for underwater image dehazing with only 0.56M parameters.</li>
    <li>Formulated a custom loss function tailored specifically for underwater image dehazing tasks.</li>
    <li>Explored the hybrid RGB-LAB color space transformations and its conversion to spike-based representations for the first time for developing a domain-aware haze removal approach.</li>
    <li>Demonstrated an improvement of 3.3× to 62.6× in energy efficiency compared to the existing vision transformer-based UIE methods.</li>
  </ul>
  <p><a href="https://arxiv.org/abs/2504.11482" target="_blank">Read the related article for more details.</a></p>
    </div>

    <div class="sub-project">
      <p><strong><em>Hybrid CNN-SNN based algorithm for multimodal pose estimation of underwater vehicles</em></strong></p>
      <img src="images/neurovio.png" alt="NeuroVIO">
      <p class="sub-project-description"> We present NeuroVIO, a hybrid end-to-end architecture that integrates convolutional neural networks (CNNs) and spiking neural networks (SNNs) for multimodal visual-inertial odometry in underwater mobile robots. Accurate pose estimation is critical for underwater robotics and exploration. In NeuroVIO, CNNs extract visual features from consecutive image frames, which are transformed into time-dependent sequences. These sequences are then processed using adaptive leaky-integrate-and-fire neurons with learnable thresholds to generate spike representations. Simultaneously, inertial measurements captured between frames are fed to an SNN-based feature extractor. The visual and inertial features are then fused and passed through an LSTM network to capture temporal dynamics, followed by an SNN-based regression head to estimate the relative pose of the vehicle. NeuroVIO leverages both CNNs and SNNs to provide comparable pose estimation accuracy while introducing sparsity in feature representations to reduce computational complexity.</p>
<ul>
    <li>Developed an end-to-end trainable model based on the hybrid CNN-SNN framework for multimodal pose estimation in underwater environments.</li>
    <li>Enable direct optimization of the integrated system by training the hybrid model as a unified framework, simplifying the overall training pipeline.</li>
    <li>Utilizes ALIF neurons to convert continuous visual features into sparse spike representations, significantly reducing computational complexity.</li>
  </ul>
  <p><a href="https://ieeexplore.ieee.org/document/10979088" target="_blank">Read the related article for more details.</a></p>
    </div>

<div class="sub-project">
      <p><strong><em>SNN-based controller for Underwater Vehicles</em></strong></p>
      <p class="sub-project-description"> </p>
<ul>
    <li></li>
  </ul>
  <p><a href="" target="_blank"></a></p>
    </div>

  </main>

  <main>
    <h2>Neuromorphic Computing for Olfaction Sensing Robots</h2>
    <div class="sub-project">
      <p><strong><em>SNN Based Odor Classification and Concentration Estimation </em></strong></p>
      <img src="images/odor_class.jpg" alt="odor_class">
      <p class="sub-project-description">This study introduces a hybrid approach for odor classification and quantification in the presence of drift. Our proposed approach employs neuromorphic principles for energy efficient operation along with the probabilistic nature of Bayesian learning for robust outcomes. Our model demonstrates superior performance compared to non-neuromorphic methods. The neuromorphic classification component of this research was initially presented at the IEEE International Conference on Robotics and Automation (ICRA) 2024. Building upon that foundation, this paper expands our previous work by integrating concentration estimation using a spike based regression method and further refining the model’s performance evaluation across various scenarios. Moreover, a robustness analysis of the proposed architecture under adversarial attack in comparison with a non-spiking algorithm is also carried out in this paper. Our work introduces several key innovations aimed at enhancing robustness, accuracy, and energy efficiency in olfactory sensing for autonomous robotics. Our classification model integrates a spike-based convolutional neural network (SCNN) for drift-independent feature extraction, which achieves domain-independent drift compensation. This CNN-driven feature extraction is complemented by a Bayesian classifier, which leverages Kullback-Leibler (KL) divergence to handle non-linear sensor response variability, significantly strengthening classification robustness. For efficient and accurate chemical concentration estimation, we introduce a non-linear SNN regression model that operates independently of chemical categories, streamlining quantification by relying solely on resistance values. We analyze the system’s computation energy requirements to assess its efficiency in comparison to non-spiking approaches. Additionally, we evaluate the model’s resilience against adversarial attacks, specifically using the fast gradient sign method (FGSM), demonstrating enhanced robustness compared to traditional CNNs.</p>
  <p><a href="https://ieeexplore.ieee.org/abstract/document/10611648" target="_blank">Read the related article for more details.</a></p>
    </div>

<div class="sub-project">
      <p><strong><em>Bio Inspired Home Localization</em></strong></p>
      <img src="images/home_loc.jpg" alt="home_loc">
      <p class="sub-project-description">In this model, we implement the home localization algorithm proposed earlier for frame-based cameras with conventional neural networks. However, we extend this framework by replacing frame-based images with event-based input and substituting the conventional convolutional neural networks with spiking convolutional neural networks (spiking CNNs). Moreover, the simulation environment is developed in ISAAC Sim on a digital twin of the Khalifa University SAN Campus. The quadrotor model used for localization tasks is adopted from the Pegasus Simulator, ensuring a realistic and dynamic testing ground for our approach. In the proposed system, event-based sensors capture changes in the environment to create spatiotemporal patterns, which are processed using spiking neural networks trained to identify key features and spatial cues within the home. This bio-inspired methodology offers several advantages, including efficient computation, robustness to noise, and adaptability to changing environmental conditions. Simulated environments provide an ideal testing ground for developing and validating the system, allowing controlled experimentation and benchmarking against traditional methods. Through this work, we demonstrate the potential of bioinspired technologies to revolutionize localization systems, paving the way for their adoption in autonomous robots, assistive technologies, and energy-efficient smart home systems. The primary contributions of this work are: </p>
<ul>
    <li>Setting up a simulation environment containing SAN campus digital twin and a quadrotor.</li>
    <li>Event-Driven Visual Sensing: Our system employs event-based cameras to mimic the asynchronous change driven sensing of insect eyes, offering robustness to changes in lighting and dynamic environments.</li>
    <li>Spiking Neural Network for Homing Vector Estimation: We employ an S-CNN to process event-driven data, where the neural architecture mimics the spike-driven computation observed in biological neurons. </li>
  </ul>
  <p><a href="https://ieeexplore.ieee.org/document/10979075" target="_blank">Read the related article for more details.</a></p>
    </div>
  </main>

<main>
    <h2>Neuromorphic Computing for Edge AI Applications</h2>
    <ul>
      <li>In collaboration with Intel Neuromorphic Research Lab</li>
      <!-- …etc… -->
    </ul>
  </main>

<footer>
    <p> NC4Robotics Lab </p>
    <p> Contact: nc4robotics@gmail.com </p>
  </footer>
</body>
</html>

=======

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Research</title>
    <!-- favicons Icons -->
    <link rel="apple-touch-icon" sizes="180x180" href="assets/images/favicons/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicons/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicons/favicon-16x16.png" />
    <link rel="manifest" href="assets/images/favicons/site.webmanifest" />
    <meta name="description" content="IT Solutions & Technology HTML Template " />

    <!-- fonts -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>

    <link href="https://fonts.googleapis.com/css2?family=Space+Grotesk:wght@300..700&display=swap" rel="stylesheet">


    <link href="https://fonts.googleapis.com/css2?family=Marcellus&display=swap" rel="stylesheet">


    <link rel="stylesheet" href="assets/css/bootstrap.min.css" />
    <link rel="stylesheet" href="assets/css/animate.min.css" />
    <link rel="stylesheet" href="assets/css/custom-animate.css" />
    <link rel="stylesheet" href="assets/css/swiper.min.css" />
    <link rel="stylesheet" href="assets/css/font-awesome-all.css" />
    <link rel="stylesheet" href="assets/css/jarallax.css" />
    <link rel="stylesheet" href="assets/css/jquery.magnific-popup.css" />
    <link rel="stylesheet" href="assets/css/odometer.min.css" />
    <link rel="stylesheet" href="assets/css/flaticon.css">
    <link rel="stylesheet" href="assets/css/owl.carousel.min.css" />
    <link rel="stylesheet" href="assets/css/owl.theme.default.min.css" />
    <link rel="stylesheet" href="assets/css/nice-select.css" />
    <link rel="stylesheet" href="assets/css/jquery-ui.css" />
    <link rel="stylesheet" href="assets/css/aos.css" />
    <link rel="stylesheet" href="assets/css/twentytwenty.css" />


    <link rel="stylesheet" href="assets/css/module-css/banner.css" />
    <link rel="stylesheet" href="assets/css/module-css/slider.css" />
    <link rel="stylesheet" href="assets/css/module-css/footer.css" />
    <link rel="stylesheet" href="assets/css/module-css/services.css" />
    <link rel="stylesheet" href="assets/css/module-css/sliding-text.css" />
    <link rel="stylesheet" href="assets/css/module-css/about.css" />
    <link rel="stylesheet" href="assets/css/module-css/counter.css" />
    <link rel="stylesheet" href="assets/css/module-css/portfolio.css" />
    <link rel="stylesheet" href="assets/css/module-css/process.css" />
    <link rel="stylesheet" href="assets/css/module-css/contact.css" />
    <link rel="stylesheet" href="assets/css/module-css/testimonial.css" />
    <link rel="stylesheet" href="assets/css/module-css/brand.css" />
    <link rel="stylesheet" href="assets/css/module-css/newsletter.css" />
    <link rel="stylesheet" href="assets/css/module-css/team.css" />
    <link rel="stylesheet" href="assets/css/module-css/pricing.css" />
    <link rel="stylesheet" href="assets/css/module-css/event.css" />
    <link rel="stylesheet" href="assets/css/module-css/blog.css" />
    <link rel="stylesheet" href="assets/css/module-css/why-choose.css" />

    <!-- template styles -->
    <link rel="stylesheet" href="assets/css/style.css" />
    <link rel="stylesheet" href="assets/css/e-style.css" />
    <link rel="stylesheet" href="assets/css/responsive.css" />

    <script src="assets/js/preload.js"></script>
    <script src="assets/js/research-gallery.js"></script>
</head>

<body id="ResearchPage">
    <!--Start Preloader-->
    <div class="loader js-preloader">
        <div></div>
        <div></div>
        <div></div>
    </div>
    <!--End Preloader-->

    <div class="page-wrapper">
        <header class="main-header-two">

            <div class="main-menu-two__top">

                <div class="main-menu-two__top-inner">
                    <p class="main-menu-two__top-text">Welcome to KU's Neuromorphic Computing for Robotics & AI Lab</p>
                    <ul class="list-unstyled main-menu-two__contact-list">
                        <li>
                            <div class="icon">
                                <i class="icon-pin"></i>
                            </div>
                            <div class="text">
                                <p>Abu Dhabi, UAE</p>
                            </div>
                        </li>
                        <li>
                            <div class="icon">
                                <i class="icon-search-mail"></i>
                            </div>
                            <div class="text">
                                <p><a href="mailto:nc4robotics@gmail.com">nc4robotics@gmail.com</a>
                                </p>
                            </div>
                        </li>
                    </ul>
                </div>
            </div>
            <nav class="main-menu main-menu-two">
                <div class="main-menu-two__wrapper">
                    <div class="main-menu-two__wrapper-inner">
                        <div class="main-menu-two__left">
                            <div class="main-menu-two__logo">
                                <a href="index.html"><img src="assets/images/resources/logo.png" alt=""></a>
                                <a href="https://ku.ac.ae"><img src="assets/images/resources/ku-logo.png" alt=""
                                        style="opacity: 0.85;"></a>
                            </div>
                        </div>
                        <div class="main-menu-two__main-menu-box">
                            <a href="#" class="mobile-nav__toggler"><i class="fa fa-bars"></i></a>
                            <ul class="main-menu__list">
                                <li>
                                    <a href="index.html">Home</a>
                                </li>
                                <li class="current">
                                    <a href="research.html">Research</a>
                                </li>
                                <li class="dropdown">
                                    <a>Tutorial</a>
                                    <ul class="shadow-box">
                                        <li>
                                            <a>
                                                <p>Basics
                                                    <span>(Coming Soon)</span>
                                                </p>
                                            </a>
                                        </li>
                                        <li>
                                            <a>
                                                <p>Spike Coding of Continuous-Values Sensor Data
                                                    <span>(Coming Soon)</span>
                                                </p>
                                            </a>
                                        </li>
                                    </ul>
                                </li>
                                <li>
                                    <a href="team.html">Team</a>
                                </li>
                                <li>
                                    <a href="about.html">About</a>
                                </li>
                            </ul>
                        </div>
                    </div>
                </div>
            </nav>
        </header>
        <div class="stricky-header stricked-menu main-menu main-menu-two">
            <div class="sticky-header__content"></div><!-- /.sticky-header__content -->
        </div><!-- /.stricky-header -->


        <!--Research Topics Start-->
        <div class="container content" id="researchContent">
            <div class="row title">
                <div class="col-lg-12">
                    <div class="section-title__tagline-shape-1"></div>
                    <span class="section-title__tagline">Research Topics</span>
                    <div class="section-title__tagline-shape-2"></div>
                </div>
            </div>
            <div class="row row-cols-3" id="researchTopics"></div>
            <div class="row row-cols-lg-2 row-cols-1" id="researchArticles">
            </div>
        </div>


    </div><!-- /.page-wrapper -->



    </div><!-- /.page-wrapper -->

    <div class="mobile-nav__wrapper">
        <div class="mobile-nav__overlay mobile-nav__toggler"></div>
        <!-- /.mobile-nav__overlay -->
        <div class="mobile-nav__content">
            <span class="mobile-nav__close mobile-nav__toggler"><i class="fa fa-times"></i></span>

            <div class="logo-box">
                <a href="index.html" aria-label="logo image"><img src="assets/images/resources/logo-2.png" width="150"
                        alt="" /></a>
            </div>
            <!-- /.logo-box -->
            <div class="mobile-nav__container"></div>
            <!-- /.mobile-nav__container -->

            <ul class="mobile-nav__contact list-unstyled">
                <li>
                    <i class="fa fa-envelope"></i>
                    <a href="mailto:needhelp@packageName__.com">nc4robotics@gmail.com</a>
                </li>
            </ul><!-- /.mobile-nav__contact -->

        </div>
        <!-- /.mobile-nav__content -->
    </div>
    <!-- /.mobile-nav__wrapper -->

    <a href="#" data-target="html" class="scroll-to-target scroll-to-top">
        <span class="scroll-to-top__wrapper"><span class="scroll-to-top__inner"></span></span>
        <span class="scroll-to-top__text"> Go Back Top</span>
    </a>

    <div class="gallery-wrapper" id="galleryWrapper"></div>

    <script src="assets/js/jquery-3.6.0.min.js"></script>
    <script src="assets/js/bootstrap.bundle.min.js"></script>
    <script src="assets/js/jarallax.min.js"></script>
    <script src="assets/js/jquery.ajaxchimp.min.js"></script>
    <script src="assets/js/jquery.appear.min.js"></script>
    <script src="assets/js/swiper.min.js"></script>
    <script src="assets/js/jquery.magnific-popup.min.js"></script>
    <script src="assets/js/jquery.validate.min.js"></script>
    <script src="assets/js/odometer.min.js"></script>
    <script src="assets/js/wNumb.min.js"></script>
    <script src="assets/js/wow.js"></script>
    <script src="assets/js/isotope.js"></script>
    <script src="assets/js/owl.carousel.min.js"></script>
    <script src="assets/js/jquery-ui.js"></script>
    <script src="assets/js/jquery.nice-select.min.js"></script>
    <script src="assets/js/twentytwenty.js"></script>
    <script src="assets/js/jquery.event.move.js"></script>
    <script src="assets/js/marquee.min.js"></script>
    <script src="assets/js/jquery.circleType.js"></script>
    <script src="assets/js/jquery.fittext.js"></script>
    <script src="assets/js/jquery.lettering.min.js"></script>
    <script src="assets/js/typed-2.0.11.js"></script>
    <script src="assets/js/jquery-sidebar-content.js"></script>
    <script src="assets/js/aos.js"></script>
    <script src="assets/js/countdown.min.js"></script>




    <script src="assets/js/gsap/gsap.js"></script>
    <script src="assets/js/gsap/ScrollTrigger.js"></script>
    <script src="assets/js/gsap/SplitText.js"></script>

    <!-- template js -->
    <script src="assets/js/script.js"></script>

</body>

</html>
>>>>>>> b5fa598 (website v0.2)
